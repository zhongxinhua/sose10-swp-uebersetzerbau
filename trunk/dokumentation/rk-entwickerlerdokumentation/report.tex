\documentclass[10pt,a4paper,ngerman,titlepage,tocindentauto]{scrartcl}

\usepackage{jhla4}
\usepackage[T1]{fontenc}
\usepackage[utf8x]{inputenc}
\usepackage{color}
\usepackage[colorlinks=true,breaklinks=true,linkcolor=darkblue,urlcolor=darkblue]{hyperref}
\usepackage{ngerman}
\usepackage{libertine}
\usepackage{graphicx}
\usepackage{tocstyle}
\usepackage{multicol}
\usepackage{listings}
\usepackage{wrapfig}
\usepackage{placeins}

\hypersetup{
	pdftitle={Software Projekt Uebersetzerbau 2010: Entwicklerdokumentation},
	pdfauthor={Rene Kijewski},
	pdfsubject={},
	pdfcreator={},
	pdfproducer={},
	pdfkeywords={},
	pdfkeywords={}
}

\definecolor{darkblue}{rgb}{0,0,0.5}
\definecolor{crimson}{rgb}{0.862745098,0.0784313725,0.235294118}

\usetocstyle{allwithdot}
\setcounter{tocdepth}{3}
\setcounter{secnumdepth}{3}

\renewcommand{\listfigurename}{Abbildungsverzeichnis}
\renewcommand{\lstlistingname}{Quelltext}
\renewcommand{\lstlistlistingname}{Quelltextverzeichnis}

\newcommand{\xmlNote}[2]{\footnote{Spezifikation zu \href{http://www.w3.org/TR/2008/REC-xml-20081126/\#{#1}}{\texttt{#2}}.}}
\newcommand{\link}[1]{\href{#1}{#1}}
\newcommand{\TODO}{ {\LARGE\bf\color{crimson} TODO} }
\newcommand{\n}{\linebreak[1]}
\newcommand{\java}[1]{\lstinline[language=java,showstringspaces=true]{#1}}

\begin{document}
	\begin{titlepage}
		\titlehead{\includegraphics[width=\textwidth]{graphiken/Fub-logo.pdf}}
		\title{Softwareprojekt Übersetzerbau 2010} 
		\subtitle{Entwicklerdokumentation --- Abschlussbericht}
		\author{René Kijewski} 
		\date{30. Juli 2010 \vfill}
		\maketitle
	\end{titlepage}
	
	\begin{abstract}
		Das Softwareprojekt Übersetzerbau 2010 setzte sich zum Ziel, einen XML- nach Java"=Source"=Code"=Übersetzter
		zu schreiben.
		Dieses Dokument erklärt im Speziellen die Komponenten XML"=Lexer, Statement"=Lexer
		und die Symboltabelle. Es richtet sich an Entwickler und enthält deshalb gegebenenfalls
		Jargon und versucht auch nicht, Sachverhalte zu vereinfachen.
		Die entsprechende Kundenpräsentation, die sich nicht an Programmierer richtet, steht unter
		\href{https://dev.spline.de/svn/ss10-swp-uebersetzerbau/trunk/dokumentation/rk-kundenpraesentation/rk-kundenpraesentation.pdf}
		{https://{\n}dev.spline.de/{\n}svn/{\n}ss10-swp-uebersetzerbau/{\n}trunk/dokumentation/{\n}rk-kundenpraesentation/{\n}rk-kundenpraesentation.pdf}
		zur Verfügung.
	\end{abstract}

	{
		\pagestyle{empty}
		\tableofcontents
		\newpage
	}
	
	\parskip 7pt plus 5pt minus 3pt
%	\setcounter{page}{1}
	\section{Einleitung}
		Das Softwareprojekt Übersetzerbau 2010 machte es sich zur Aufgabe, eine selbst"=erdachte Programmiersprache
		zu spezifizieren und einen Compiler für diese zu Implementieren.
		
		Die Projektgruppe, bestehend aus -- in alphabetischer Ordnung --
			Alexander Rau,
			Ansgar Schneider,
			Igor Merkulow,
			Markus Rudolph,
			René Kijewski und
			Stefan Meißner,
		entschied sich, eine XML"=artige Eingabesprache zu benutzen, die
		\href{http://java.sun.com/javase/6/}{Java"=SE"=6}"=kompatiblen Sourcecode ausgibt.
		Dementsprechend wurde auch Java 1.6 als Programmiersprache gewählt.
		Als einheitliche Programmierungebung wurde \href{http://www.eclipse.org/galileo/}{Eclipse Galileo} verwandt.
		Apache \href{http://subversion.apache.org/}{Subversion}, gehostet bei \href{http://dev.spline.de/}{Spline}, wurde als
		Versionskontrollsystem benutzt. Der Quelltext kann von \link{https://dev.spline.de/svn/ss10-swp-uebersetzerbau/}
		heruntergeladen werden.
		
		Ich übernahm die Komponenten XML"= und Statement"=Lexer, sowie die Implementierung einer Symboltabelle.
		
		Bei den von mir implementierten Teilprojekten achtete ich auf hohe Wiederverwendbarkeit
		und versuchte, eine Benutzung besonders einfach zu gestalten. So legte ich größeren Wert darauf,
		dass Weiternutzer die Komponenten ohne lange Einlesezeit benutzen können als auf besonders große
		Performanz. Dieser Ansatz musste leider später aufgewicht werden. In den Abschnitten
		\hyperlink{Arbeitsverlauf}{Arbeitsverlauf} und \hyperlink{Abschlussbemerkungen}{Abschlussbemerkungen}
		finden Sie weitere Informationen dazu.
		
		Um den Einstieg in die Nutzung zu Vereinfachen, verwandte ich ausgiebig die verbreitete Entwurfsmuster,
		vorrangig das \href{http://c2.com/cgi/wiki?IteratorPattern}{\em Iterator"=Patter} und die
		\href{http://c2.com/cgi/wiki?FactoryMethodPattern}{\em Factory"=Methode}.
		Beide Pattern werden im Buch {\em Design Patterns: Elements of Reusable Object"=Oriented Software}%
		\footnote{ISBN \href{https://portal.d-nb.de/opac.htm?method=simpleSearch&query=0201633612}{0-201-63361-2}}
		beschrieben und sind vielen Entwicklern von objektorientiertem Code geläufig.
		
		Die einzelnen Komponenten trennen so weit wie möglich zwischen Interface und Implementierung.
		Dies sollte es bei einer späteren Weiterarbeit am Projekt vereinfachen, die Komponenten
		auszutauschen. Bei der Spezifikationsphase überlegten wir uns unter anderem, dass auch eine
		Compilierung in Java"=Bytecode nativ möglich sein sollte.%
		\footnote{Das heißt, dass wir nicht von \texttt{javac} abhängig sein wollten.}
		Zudem sollte auch die Ausgabesprache auswechselbar sein, so dass nur das Kernstück,
		der Syntaxbaum, sowie das Interface der weiteren Komponenten, also Symboltabelle und Builder,
		unveränderlich wäre.
		
	\section{Teilprojekte}
		Die einzelnen Teilprojekte sind für sich allein verwendbar -- die Verzahnung
		mit anderen Komponenten ist minimal --, da sie jeweils am Anfang der Bearbeitungskette stehen.
		
		\begin{figure}[ht]
			\caption[Verlaufdiagramm]
				{\hypertarget{Verlaufdiagramm}{Verlaufdiagramm (in diesem Dokument beschriebene Komponenten hervorgehoben)}}
			\fbox{\centering
				\includegraphics[width=\textwidth]{graphiken/flowchart.pdf}
			}
		\end{figure}
		
		Die Lexer"=Komponenten benutzen jeweils einen Zeichenstrom als Eingabe. Die Rückgabedaten speichern die
		Stelle im Eingabestrom an der sie standen, so dass spätere Komponenten, wenn sie einen Fehler
		in der Eingabe feststellen, eine geeignete Meldung samt Position ausgeben können.
		Die Symboltabelle verwendet dasselbe Interface, um die Eingabeposition zu speichern, jedoch ist
		die Bedeutung an dieser Stelle wahrscheinlich geringer als bei den Lexern.
		
		\subsection[XML"=Lexer]{\hypertarget{Teilprojekte_XML_Lexer}{XML"=Lexer}}
			Der XML"=Lexer {\em xmlNodeStream} vereinfacht die Arbeit des DOM"=Parsers, indem er die syntaxtischen
			Komponenten des Eingabestromes auftrennt, das heißt {\em tokenized}.
			Die erkannten Komponenten sind Textknoten, Kommentare, Tags, Endtags, Attribute und Processing instructions.
			
			Als Eingabeformat wird XML 1.0 verwendet.%
			\footnote{\href{http://www.w3.org/TR/2008/REC-xml-20081126/}{Extensible Markup Language (XML) 1.0 (Fifth Edition)}}
			Es wurden bewusst Eineinfachungen jedenüber dem W3-Standard vorgenommen. Unter anderem sind
			nicht wohlgeformte Ausdrücke nach Art ,,\verb|<tag attr="a < b"/>|`` erlaubt.
			Dieses Beispiel wäre aufgrund des Kleiner"=Als"=Zeichens im Attributewert
			nach der Spezifikation verboten.\xmlNote{NT-AttValue}{AttValue}
			
			Die API des {\em xmlNodeStreams} ist an {\em StAX}, der \href{http://stax.codehaus.org/}{Streaming API for XML},
			angelehnt. StAX hat sich seit der Spezifikation im \href{http://jcp.org/en/jsr/detail?id=173}{JSR 173} aus
			dem Jahr 2006 als Standard für einfaches Parsen von XML"=Eingaben etabliert.
			xmlNodeStream besitzt nicht dieselbe Mächtigkeit wie StAX und erfüllt in Folge dessen
			nicht die komplette Spezifikation des W3-Consortiums, da der XML"=Prolog\xmlNote{xmldoc}{prolog}
			nicht als solcher verstanden wird:
			\begin{itemize}
				\item
					Die XML"=Deklaration\xmlNote{NT-XMLDecl}{XMLDecl} wird als
					Processing instruction\xmlNote{NT-PI}{PI} verstanden.
				\item
					Die Doctype"=Deklaration\xmlNote{NT-doctypedecl}{doctypedecl} wird nicht unterstützt.
			\end{itemize}
			Konkretere Informationen über den Informationsfluss stehen in der \hyperlink{XML-Lexer-API}{API"=Referenz}.
			
			Der XML"=Lexer überprüft die Eingabe nicht auf Wohlgeformtheit, das heißt, auch
			,,\verb|<a></b>|`` würde nicht nicht als Fehler erkannt. Dies ist eine bewusste Designentscheidung,
			die einerseits den Overhead durch eine solche Überprüfung verhindern soll -- der DOM"=Parser
			führt eh über eine Überprüfung durch -- und andererseits die Anwendungsmöglichkeiten der Implementierung
			verbreitern soll: Gewöhnliche Webseiten sind selten wohlgeformtes XML. Dadurch,
			dass {\em xmlNodeStream} agnostisch gegenüber Strukturfehlern ist, wäre er auch zum
			Lexen von Internetseiten geeignet. Fehler wie fehlende abschließende Anführungszeichen werden
			jedoch nicht übergangen, da sie eine aktive Fehlerkorrektur erforderten.
			
			{\em xmlNodeStream} implementiert das Iterator"=Interface Javas, wodurch der Einstieg in die
			Benutzung vereinfacht werden soll.
			
			\subsubsection*{Beispiel}
				\begin{lstlisting}[frame=single,language=XML,caption=Beispiel.xml]
<?xml version="1.0"?>
<module name="Test">
	Inhalt
</module>
				\end{lstlisting}
				Die Eingabedatei obenstehende XML"=Datei würde folgendermaßen erkannt:
				\begin{itemize}
					\item Processing instruction mit dem Namen ,,\verb|xml|`` und Wert ,,\verb|version="1.0"|``.
					\item Öffendes Tag mit dem Namen ,,\verb|module|``.
					\item Attribute mit dem Namen ,,\verb|name|`` mit dem Wert ,,\verb|Test|``.
					\item Textknoten mit dem Wert ,,\verb|Inhalt|``.
					\item Schließendes Tag mit dem Namen ,,\verb|module|``.
				\end{itemize}
				An diesem Beispiel Erkennt man, dass das jedes eingelesene Token ein Tripel aus
				Typ, Name und Wert ist, wobei Name und/oder Wert auch leer beziehungsweise \texttt{null} sein können.
			
			\begin{figure}[ht]
				\caption[Übergangstabelle der Eingabedaten]{\hypertarget{Uebergangsdiagramm_XML_Lexer}{Übergangstabelle der Eingabedaten}}
				\fbox{\centering
					\includegraphics[width=1.4\textwidth,angle=90]{graphiken/xml.pdf}
				}
			\end{figure}
			
		\subsection{Statement"=Lexer}
			Der Statement"=Lexer hat eine ähnliche Aufgabe wie der XML"=Lexer: Einen Eingabestrom in seine
			Komponenten auftrennen. Das Lexen der Statements ist die Vorstufe zum Parsen.
			
			Der Statement"=Lexer verwendet das Iterator"=Interface, wobei die Rückgabedaten
			Tupel aus dem Typen des Datums und eventuell einem zugehörigen Wert, zum Beispiel bei Strings.
			In der derzeitigen Implementierung gibt es 33 Arten von erkannten Token, sowie zwei
			Statuscodes für das Eingabeende beziehungsweise bei lexikalisch fehlerhaften Eingaben.
			Der Umfang der erkannten Eingabefehler ist gering; die Fehlererkennung geschieht im
			{\em Statement"=Parser}. Als Fehler würde unter anderem ,,\verb|1a|`` erkannt; ,,\verb|a b c|`` hingegen nicht.
			
			Die Syntax der Statements lehnt sich an Java\,SE\,6 an. Da Javas Operatoren nur ein oder
			zwei Zeichen lang sind\footnote{Der Operator \texttt{{>}>{>}} wird nicht verstanden.} und es keine Zustände wie beim
			Lexen von XML"=Daten wird, wird keine Übergangstabelle benutzt, sondern ein \verb|switch|"= und
			\verb|if|"=Konstrukt. Dies vereinfacht im Allgemeinen sowohl das Lesen und Schreiben des Lexers,
			erschwert jedoch Spezialfälle. So wird zum Beispiel zum Erkennen der Token \verb|new| und
			\verb|null| auf Tricks wie Push"=Back"=Buffer zurückgegriffen.
			Ein entscheidender Vorteil ist jedoch, dass das Einlesen der Daten wesentlich schneller
			als beim XML"=Lexer geschieht.
	
		\subsection{Symboltabelle}
			Die Symboltabelle ist die zentrale Speicherstelle der in der Eingabe vorkommenden Symbole.
			Symbole sind hierbei unter anderem Packages, Klassen und Methoden, jedoch auch Scopes und und \texttt{void}.
			Hiermit steht sie parallel zum Syntaxbaum. Der Annotator stellt die Schnittstelle zwischen beiden
			Komponenten dar.
			
			Ebenso wichtig wie den Einblick in die Symbole des Eingabecodes zu haben, ist die Schnittstelle
			zum Zielsystem. So ,,kennt`` die Symboltabelle unter anderem die nativen Typen des Zielsystems und
			,,weiß``, was verbotene Bezeichner sind beziehungsweise kann Bezeichner für das Zielsystem
			dekorieren. Die Symboltabelle ,,merkt sich`` Referenzierungen von Symbolen, die an der Stelle, in
			der sie im Quelltext auftraten, noch nicht definiert waren. Diese Symbole bezeichnet man als
			{\em unqualified}. Dem gegenüber sind bekannte Symbole {\em qualified}. Unqualified Symbols können
			unter anderem dann auftreten, wenn eine Funktion \texttt{a()} eine Funktion \texttt{b()} aufruft
			und \texttt{b()} wiederum \texttt{a()}.
			
			Die Symboltabelle arbeitet in drei Phasen:
			\begin{enumerate}
				\item
					Aufbau des Grundsystems, das heißt, dass der Sichtbarkeitsraum mit den primitiven
					Datentypen gefüllt wird --- bei Java also unter anderem \texttt{int} und \texttt{float}.
					Im nächsten Schritt werden die Symbole des Zielsystems eingelesen, was im Falle von
					Java unter anderem \texttt{java.lang.String}. Nach dem Einlesen der Symbole des
					Zielsystems wird der Kontrollfluss an den Builder abgegeben.
				\item
					Im nächsten Schritt wird die Symboltabelle mit den Symbolen aus der Eingabedatei befüllt.
					Die Symboltabelle erkennt an dieser Stelle die Verwendung von ungültigen Bezeichnern und weist
					sie ab. Nachdem der Struktur der Eingabe in der Symboltabelle wiedergegeben wurde, wird versucht
					sämtliche Symbole zu qualifizieren.
				\item
					Die letzte Phase stellt die Anwendung der Symboltabelle dar, in der der Builder sie unter anderem
					Benutzt, um die Datentypen von Symbolen zu erkennen, da Operatoren wie \texttt + je nach Datentyp
					eine andere Bedeutung haben. Sollte in der letzten Phase noch ein unqualified Symbol auftreten
					so muss dem Benutzer durch den Builder eine geeignete Fehlermeldung ausgegeben werden.
			\end{enumerate}
	
	\section[Arbeitsverlauf]{\hypertarget{Arbeitsverlauf}{Arbeitsverlauf}}
		Die Programmierung des XML"=Lexers wurde bereits am 30. April begonnen; die Komponente ist deshalb
		wohl am ausführlichsten getestet. Die Aufgabe des Statement"=Lexers wiederum wurde
		am 19. Mai begonnen und die Arbeit an der Symboltabelle wurde am 28. Mai aufgenommen,
		wudurch gerade für die letzte Aufgabe ein erheblicher Zeitdruck bestand.
		
		\subsection{XML"= und Statement"=Lexer}
			Die Arbeit am XML"=Lexer verlief verhältnismäßig zielgerichtet. In der Vorlesung
			Übersetzerbau wurde ausgiebig erklärt, wie ein Parser geschrieben wird, so dass
			sich die tatsächliche Umsetzung als einfach erwies. Probleme ergaben sich nur,
			wenn ich Übergänge im Zustandsdiagramm (siehe \hyperlink{Uebergangsdiagramm_XML_Lexer}{Abbildung 2})
			übersah, weshalb ich sehr schnell dazu überging, das Diagramm in der Sprache
			\href{http://www.graphviz.org/doc/info/lang.html}{DOT} festzuhalten. Zeichnungen auf
			dem Papier erwiesen sich nicht als sachdienlich.
		
			Der Statement"=Lexer wurde in kurzer Zeit geschrieben, da die Aufgabe wesentlich einfacher als beim
			XML"=Lexer war. Wo beim XML"=Lexer ein Zustand mitgeführt werden muss, der zum Beispiel vermerkert, ob
			man sich derzeit in der Mitte zwischen einem ,,\verb|<|`` und ,,\verb|>|`` befindet, existieren solche Schwierigkeiten
			beim Statement"=Lexer nicht. Die zu implementierenden Operatoren habe ich unserem Notizblatt im
			\href{http://pad.spline.de/ep/pad/view/ro.v9mc/rev.9252}{Spline"=Pad} entnommen.
		
		\subsection{Symboltabelle}
			Die Arbeit an der Symboltabelle erwies sind als kompliziert. Da die Aufgabe leider sehr spät erst
			vergeben wurde und aufgrund der Anforderung, dass sie Typisierung beherrschen sollte, gehörte
			die Symboltabelle planerisch zu den größten Komponenten.
			
			Die Symboltabelle sollte zunächst für sämtlichen Zielsprachen gleich implementiert sein. Nachdem
			ich mich jedoch weiter in die Thematik einlas, erwies sich das nicht als möglich, da die verschiedenen
			Zielsysteme zu unterschiedlich sind. So haben verschiedene Programmiersprachen, selbst wenn man
			sich auf objektorientierte Programmiersprachen beschränkt, wenig Gemeinsamkeiten. Als Beispiele gegenüber
			Java sei die prototypen"=basiere
			Programmiersprache \href{http://www.ecma-international.org/publications/standards/Ecma-262.htm}{ECMAScript}
			und ihre unterschiedlichen Implementierungen wie Javascript
			angeführt, deren Klassenkonzept keine Gemeinsamkeiten mit Java aufweist, jedoch sinnvolle Zielsprachen
			wären.
			
			Ich beschränkte mich auf die Umsetzung einer Symboltabelle, die Java 1.6 sowohl für die Ausgabe
			nach Quelltext als auch Bytecode beherrt. Das Interface wiederum sollte so generisch gehalten werden,
			dass später weitere Zielsysteme eingeführt werden könnten, wobei sich ein zu generischen Interface
			als zu kompliziert -- und damit als unbenutzbar -- erwies. Herr Rudolf gab mir des Öfteren hinweise
			auf Verbesserungsmöglichkeiten am Interface, die mir zuvor nicht einfielen. Wiederum war das Interface
			dadurch während der gesamten Entwicklungszeit einem ständigen Wandel unterlegen, wobei ich mir eigentlich
			eine schnelle Festlegung wünschte, gegen die ich die konkrete Implementierung entwickeln könnte.
			Retrospektiv kann ich sagen, dass ich mich anfangs zu wenig mit meinen anderen Teammitgliedern
			zusammengesetzt habe und deshalb nicht die Fülle der Anforderungen kannte.
			
			Bei der Programmierung an der Symboltabelle habe ich einige wertvolle Kenntnisse über die Interna
			Javas gewonnen. Gerade bei der Reflexion"=API, die einem Programm zur Laufzeit Informationen über
			das Klassen"= beziehungsweise Typsystem geben soll, habe ich erhebliche Wissensprünge gemacht,
			die ich auch für andere Kurse nutzen konnte.\footnote{Siehe zum Beispiel \href
			{https://dev.spline.de/svn/xmlproject10-group-x/trunk/controller/src/java/de/spline/dev/xmlproject10_group_x/imports/xmlContainers/Container.java}
			{\texttt{Containers.java}} des XML"=Technologien"=Projekts} Leider erwies sich die sehr einfach zu
			benutzende Reflexions"=API als Haupt"=Flaschenhals des gesamten Projektes, weshalb ich einige ,,halbherzige``
			Behelfsmaßnahmen eingebaut habe -- {\em halbherzig} deshalb, weil ich das Problem nur versteckt und
			nicht beseitigt habe. Die Reflexions"=API ist leider äußerst langsam und verbraucht große Mengen an
			RAM"=Speicher, da die Inspizierten Klassen, sowie sämtliche (transitiven) Abhängigkeiten in den Speicher
			geladen werden, wobei eigentlich nur die Struktur der Klasse bedeutsam für die Erfüllung der Aufgabe wäre.
			
			Als erste Behelfsmaßnahme werden nur noch Klassen in die Symboltabelle gelesen, die auch von außen sichtbar
			sind, das heißt entweder \texttt{public} oder \texttt{protected} sind. Default"=Private und \texttt{private}"=Klassen
			werden nicht mehr eingelesen. Jedoch offenbart diese Beschreibung bereits das größte Problem dieser Umsetzung:
			Nur weil Klassen nicht adressierbar {\em wäre}, gilt das nicht für zum Beispiel Rückgabewerte. Als weitere
			Maßnahme zum Beschleunigen habe ich das Laden pa\-ral\-le\-li\-siert, wodurch sich -- gefühlt -- ein fast linearer Anstieg
			der Geschwindigkeit mit der Zahl der Benutzen Rechenkernen ergab.
	
	\section{Offene Baustellen}
		Leider blieben aufgrund der geringen Projektdauer noch einige Komponenten fehlerhaft oder unvollständig.
		Jene Verbesserungsvorschläge, die mir einfielen, hielt ich im \href
		{https://dev.spline.de/svn/ss10-swp-uebersetzerbau/trunk/dokumentation/Offene\%20Baustellen.txt}
		{\texttt{Offene Baustellen.txt}} beziehungsweise als \texttt{TODO}s an der Entsprechenden Stelle im
		Quelltext fest. Die einzelnen Teilprojekte sind noch nicht ausreichend durch Unittests überprüft worden.
		Bei einer Weiterarbeit an dem Projekt täten folgende Programmierer gut daran, zuerst Blackbox-Text
		der einzelnen Komponenten durchzuführen, um eventuelle Verstöße gegen das Interface festzustellen.
	
		\subsection{XML"=Lexer}
			Der XML"=Lexer steht an erster Stelle in der des \hyperlink{Verlaufdiagramm}{Arbeitsablaufes} und kann deshalb,
			trotz des Fehlens formeller Unittests als überprüft betrachtet werden. Eventuelle Fehler hätten sich
			beim Gebrauch zeigen sollen.
			
			Offen ist noch die komplette Implementierung des XML"=1.0"=Standards, wie bereits
			\hyperlink{Teilprojekte_XML_Lexer}{oben erwähnt}, wobei meines Erachtens der Mehrwert
			durch die vollständige Implementierung des Standars nicht der Aufwand rechtfertigen
			würde.
	
		\subsection{Statement"=Lexer}
			Der Statement"=Lexer enthält noch einen dokumentierten Fehler, dessen Ursache noch nicht ausgemacht werden konnte.
			Der Bezeichner ,,\texttt{nul}`` ist nicht erlaubt, was mit der Implementierung der Erkennung des Keywords
			\texttt{null} zusammenhängen wird. Das Erkennen der Schlüsselwörter ist derzeit suboptimal implementiert, da
			mir leider bei bei der Arbeit an der Symboltabelle ein besserer Algorithmus einfiel.
			
			Derzeit werden wird die Eingabe mit einem Pushback"=Buffer eingelesen. Sollten Zeichen gelesen werden,
			die nicht zu dem derzeitigen Token gehören, werden sie wieder in den Eingabestrom zurückgeschrieben.
			Sollte nur ein Zeichen zurückgeschrieben werden müssen, arbeitet diese Methode performant und ist zudem
			einfach zu implementieren. Sollten jedoch mehr Zeichen zurückzuschreiben sein, so kann sich diese Methode
			als kompliziert zu warten erweisen. Zuerst schrieb ich einen Pushback"=Buffer mit einem Zeichen als
			Pushback und schrieb ihn im weiteren Arbeitsverlauf zu einem allgemeinen Puffer um, in dem man beliebig
			viele Zeichen zurückschreiben kann. Vermutlich ist mit dabei ein Fehler unterlaufen, der in den Beobachtung
			resultiert, dass der Bezeichner ,,\texttt{nul}`` nicht erlaubt ist.
			
			Eine sinnvollere Implementierung als die gleichzeitige Überprüfung, ob in der Eingabe ein Identifier oder
			ein Schlüsselwort steht, wäre, dass zuerst nur Identifier gelesen werden und, nachdem ein vollständiges
			Token gelesen wurde, überprüft wird, ob dieses zu einem Schlüsselwort wie \texttt{null} gehört.
	
		\subsection[Symboltabelle]{\hypertarget{Offene_Baustellen_Symboltabelle}{Symboltabelle}}
			Im weiteren Programmier"= und Testverlauf erwies sich, dass die Symboltabelle optimiert werden muss, um
			nutzbar zu sein, da die Ladezeit auf Windows"=Laptops mehrere Minuten betrug. So machte es zum Beispiel -- und zwar in einem Maße,
			das mich selbst erstaunt hat -- einen Unterschied, ob eine Stringeingabe gegen $10$ oder $\log 10$ Strings verglichen
			wird, letzteres durch die Verwendung eines \verb|Set<String>|. Häufig ist der iterative Vergleich von von kleinen
			Mengen von Werten, hier zirka zehn, schneller als ein optimierter, der in $\textsf O\!\left(\log n\right)$ arbeitet,
			jedoch scheint der Vergleich von Strings in Java um mehrere Zehnerpotenzen langsamer als bei C zu sein.
			
			Um das Problem der hohen Ladezeit zu umgehen und den Speicherbedarf minimal zu halten wären zwei Ansätze,
			idealer Weise kombiniert, gangbar.
			\begin{itemize}
				\item
					Die Reflexions"=API ist zu mächtig und schwerfällig. Ein manuelles Auslesen der klassenstruktur
					auf Objekt"=Code"=Ebene ließe es zu, dass man unnötige Informationen nicht im Speicher hält beziehungsweise
					gar nicht erst einliest.
				\item
					Ein Nadelöhr stellt die
					Benutzung von \texttt{TreeMap}s dar, die ich an vielen Stellen verwende, da sie im Gegensatz zu \texttt{HashMap}s
					nicht die Gefahr von Kollisionen in sich bergen. Vermutlich ist die Datenmenge klein genug, so dass es zu keinen
					Kollisionen der Streuwerte käme. Eine Überprüfung dieser Annahme wäre jedoch erforderlich.
			\end{itemize}
	
	\section[Abschlussbemerkungen]{\hypertarget{Abschlussbemerkungen}{Abschlussbemerkungen}}
		Eine Lexion des Projektes war, dass Besprechungen notwendig sind. Noch bevor man eine Idee umsetzt, sollte man
		sich mit den betroffenen Teammitgliedern zusammen setzten und um gemeinsam die Implikationen abzuschätzen
		oder Verbesserungsvorschläge einholen zu können. Ebenso lassen sich Beschreibungen wesentlich besser vis"=à"=vis
		vermitteln als das mit Texten möglich wäre. Als Programmierer ist man häufig zu tief in der Materie drin, als dass
		man sinnvolle Fragen abschätzen könnte, die in eine Dokumentation zu schreiben wären, wodurch zudem viel Zeit
		mit dem Schreiben unnötiger Kommentare verloren geht. Ich denke, dass Pair"=Programming das Mittel der Wahl ist,
		wenn es sich zeitlich organisieren lässt. Die Kommunikation über Chat oder Telefon kann leider nicht dasselbe leisten.
		
		Die wöchentlichen Teambesprechungen habe ich als reine Zeitverschwendung empfunden, da wöchentliche
		Berichte gerade in der Anfangsphase eines Projektes -- über die das Projekt aufgrund des Zeitdrucks
		auch nicht heraus kam -- viel zu selten sind und man zu viele für einen selbst unrelevante Informationen
		anhören muss, so dass das Aufmerksamkeitsfenster bei relevanten Dingen bereits wieder geschlossen
		sein kann. Dass die Teambesprechungen in unserem Fall um acht Uhr morgens stattfanden, war der Aufmerksamkeit
		ebenso nicht zuträglich.
		
		Nichtsdestoweniger hat das Projekt Spaß gemacht, wobei leider einige -- meines Erachtens eklatante -- Fehler in
		der Planung gemacht wurden. So haben wir viel zu viel Zeit damit aufgewendet, Lexer und Parser zu schreiben, wobei
		es zu diesem Zwecke bereits viele gute Open"=Source Tools gäbe, die wir hätten stattdessen verwenden sollen.
		Tatsächlich habe ich für die Verwendung einer XML"=ähnlichen Sprache optiert, damit wir einen vorhandene
		DOM"=Parser hätten benutzen können.
		
		Ich für meinen Teil hatte mir erhofft, mehr über die Optimierung von Zwischencode zu lernen; andere Projektmitglieder
		wiederum wollten eine Programmiersprache mit neuartigen Konzepten schaffen, wobei ich gerade Herrn Rudolfs Konzept einer
		Zustandsmaschine interessant fand. Ebenso hörte sich das Konzept einer einsteigerfreundlichen Programmiersprache gut an.\footnote
		{Ich muss gestehen, dass ich den Namen des Diplomstudierenden vergessen habe.}
		Retrospektiv muss ich sagen, dass wir uns als Gruppe zu wenig Zeit genommmen haben, uns über die Möglichkeiten
		klarzuwerden. Leider haben wir die Konzeptphase zu schnell abschließen wollen, wobei ich jedoch hoffe, so einen
		Fehler in Zukunft nicht mehr zu machen.
		
		Im Verlauf des Projektes wurde leider klar, was wir die Planung des Projektes überstürzt hatten und viele wichtige
		Komponenten nicht formell aufgeschrieben oder schlichtweg übersehen haben. Teilweise kam es zu unnötigen Leerlaufphasen,
		da es scheinbar zu jedem Zeitpunkt keine Aufgabe gab. Erst in weiteren Gesprächen wurde klar, welche Dinge noch zu tun
		wäre. So wurde unter anderem die Aufgabe der Symboltabelle bei der Aufgabenverteilung erkannt, jedoch nicht vergeben,\footnote
		{Siehe Stand der Besprechung vom \href{http://pad.spline.de/ep/pad/view/ro.v9mc/rev.7990}{7. Mai} im Spline"=Pad}
		so dass sie später vergessen wurde. Dass später seitens der Teamleiter angemerkt wurde, dass der generierte Code
		typensicher sein solle und die Symboltabelle dies sicherstellen soll, war dann ein umso größerer ,,Schock`` für mich.
		
		Zur Eskalation am Ende des Projektes hat meinerseits gerade geführt, dass das Projekt nicht die Dinge umfasste,
		die wir uns am Anfang vorgestellt haben. Ich wollte Probleme offen ansprechen, um sie eventuell besser angehen zu
		können --- Probleme, die nicht angesprochen werden, werden sich nur vergrößern. Leider ist mein Ton wohl zu aggressiv
		rübergekommen,\footnote{Vermutlich war er aggressiv, was jedoch nie meine Intention war.}
		wodurch ich jene Problem wohl nur noch verstärkt habe. Ferner jedoch hat die strikte Trennung zwischen
		,,Management`` und den Programmieren zur Eskalation beigetragen oder sie erst möglich gemacht. Es bestand ein großes
		Misstrauen zwischen uns und dem ,,Management``, unter anderem geschuldet dadurch, dass uns nicht mitgeteilt wurde,
		was in den Wochenbesprechungen zwischen den Teamleitern und Frau Fehr beredet wurde,\footnote{Meine Haupsorge an dieser
		Stelle war, dass unsere Bearbeitungsstand als besser als er war weitergegeben wurde, so dass ein mäßiges Ergebnis
		beim Projektende umso schlechter auf uns zurückfalle würde.} sowie dass uns Programmierern
		die Dokumentationen und Berichte nicht ausgehängigt wurde,\footnote{Das Spline"=Pad war nie als normativ angedacht,
		weshalb sich die Teamleiter bereit erklärten sich, eine formelle Definition zu schreiben. Es war deshalb unverständlich
		für mich, warum uns diese Arbeitsgrundlage vorenthalten wurde.} als wir danach fragten. Die strikte Weigerung der Teamleiter
		uns ihren Bearbeitungsstand der Dokumentation mitzuteilen erweckte bei uns Entwicklern den Eindruck, das Ansgar und
		Igor keine Aufgaben im Projekt übernähmen. Die Antwort, dass sie sich jede Woche nach dem Gruppengespräch für eine
		Stunde mit Frau Fehr träfen, wirkte für mich regelrecht höhnisch. Meines Erachtens ist an dieser Stelle wesentlich
		mehr Transparenz nötig.
		
		Ich denke, dass es für weitere Softwareprojekte wichtig ist, die Teamleitung dazu anzuhalten, sich auch in die
		Programmierung einzubringen, da ansonsten die Stimmung {\em unweigerlich} kippen {\em muss}. Dennoch denke ich,
		dass ich durch dieses Softwareprojekt eine Erfahrung fürs Leben gemacht habe --- mehr als es ein Besuch der
		\href{https://www.inf.fu-berlin.de/w/SE/VorlesungSoftwaretechnik2008}{Vorlesung Softwaretechnik} je könnte.
		
	\section{API"=Referenz}
		\subsection[XML-Lexer]{\hypertarget{XML-Lexer-API}{XML"=Lexer}}
			Der XML"=Lexer trennt zwischen Interface und Implementierung.
			Das Package des Interfaces heißt \texttt{de.{\n}fu\_berlin.{\n}compilerbau.{\n}xml\-Node\-Stream};
			die Implementierung befindet sich unter \texttt{de.{\n}fu\_berlin.{\n}compilerbau.{\n}xml\-Node\-Stream.{\n}impl}.
			
			\subsubsection*{Interface}
				\begin{wrapfigure}{R}{0.3\textwidth}
					\caption{Mög\-li\-che Rück\-ga\-be\-wer\-te des State\-ment"=Le\-xers nach Zu\-stand}
					\fbox{\centering
						\includegraphics[width=0.3\textwidth]{graphiken/Ausgaben.pdf}
					}
				\end{wrapfigure}
				
				Das Interface defininiert in \texttt{NodeType.java} die Arten der zu erkennenden Knoten.
				Dies sind derzeit \texttt{NT\_TEXT}, \texttt{NT\_COMMENT}, \texttt{NT\_TAG}, \texttt{NT\_END\_TAG},
				\texttt{NT\_ATTR}, \texttt{NT\_PI}, sowie für fehlerhaften Eingaben \texttt{NT\_ERROR}.
				
				Ein einzelnes gelesenes Token wird in einem \texttt{XmlNode} zurückgegeben, welches die Methoden
				\texttt{NodeType getType()}, \texttt{PositionString getKey()} und \texttt{PositionString getValue()}
				besitzt. Nicht für alle Tokenarten sind sowohl Key also auch Value gesetzt. Konsultieren dafür
				bitte das entsprechende JavaDoc für \texttt{XmlNode}. Ein \texttt{XmlNode} implementiert das Interface
				\texttt{StreamPosition}.
				
				Die letzte Komponente des Interfaces des XML"=Lexers stellt \texttt{XmlNodeStream} dar, welches
				angibt, dass die XmlNodeStreams das Interface \texttt{Iterable<{\n}XmlNode>}, \texttt{StreamPosition} und
				\texttt{Closeable} erfüllen müssen.
				
				Wie in Abbildung 3 zu sehen, kann der XmlNodeStream nicht an jeder Stelle ein beliebiges Token zurückgeben.
				So kann unter anderem \texttt{NT\_ATTR} nur auf \texttt{NT\_ATTR} oder \texttt{NT\_TAG} folgen.
				Bei der Benutzung von \texttt{XmlNodeStreamFactory} darf man sich darauf verlassen, dass dieser Contract
				nicht verletzt wird.
			
			\subsubsection*{Implementierung}
				Die Implementierung verfügt nur über eine öffentlich sichtbare Klasse, nämlich \texttt{Xml\-Node\-Stream\-Factory}.
				Die Klasse verfügt über drei statische Factory"=Methoden
				\begin{itemize}
					\item \texttt{static XmlNodeStream createNewInstance(PositionString str);}
					\item \texttt{static XmlNodeStream createNewInstance(Reader reader);}
					\item \texttt{static XmlNodeStream createNewInstance(Reader reader, StreamPosition pos);}
				\end{itemize}
				Wobei die ersten beiden Methoden Wrapper für die letzte Methode darstellen.
	
		\subsection{Statement"=Lexer}
			Der Statement"=Lexer trennt zwischen Interface und Implementierung.
			Das Package des Interfaces heißt \texttt{de.{\n}fu\_berlin.{\n}compilerbau.{\n}statementLexer};
			die Implementierung befindet sich unter \texttt{de.{\n}fu\_berlin.{\n}compilerbau.{\n}statement\-Lexer.{\n}impl}.
			
			Das Interface definiert in \texttt{TokenType.java} fünfunddreißig verschiedene Arten von gelesenen Tokens,
			wobei \texttt{EOF} und \texttt{ERROR} Statusmeldungen darstellen. Die Tokenarten orientieren sich
			an der Grammatik Javas und enthalten auch keine eigenen Elemente. Jedes gelesene Token wird in einem
			\texttt{StatementNode} zurückgegeben, wobei ein Node ein Tupel aus dem Typen und optional einem Wert
			darstellt.
			Tokens tragen nur dann einen Wert, wenn sie vom Typ \texttt{ID}, \texttt{STRING}, \texttt{INT} oder
			\texttt{REAL} sind. Zum Auslesen der Werte gibt es die Methoden
			\begin{itemize}
				\item \texttt{Object getValue() throws IllegalAccessException;}
				\item \texttt{Number getNumber() throws IllegalAccessException;}
				\item \texttt{CharSequence getString() throws IllegalAccessException;}
			\end{itemize}
			Eine \texttt{IllegalAccessException} wird geworfen, wenn das Token keinen (entsprechenden)
			Wert enthält. \texttt{getNumber()} enthält nur für \texttt{INT} und \texttt{REAL} einen Wert;
			\texttt{getString()} wiederum nur für \texttt{ID} und \texttt{STRING}.
			
			Das Tokenisieren geschieht über die Factory"=Methode \texttt{StatementLexer.tokenize(Position\-Character\-Stream)},
			wobei der Rückgabewert ein \texttt{Iterable<StatementNode>} ist und somit über die Methoden \texttt{next()} und
			\texttt{hasNext()} angesprochen werden kann.
	
		\subsection{Symboltabelle}
			Das Interface der Symboltabelle liegt im Package \texttt{de.{\n}fu\_berlin.{\n}compilerbau.{\n}symbolTable}.
			Die Implementierung ist -- wie der eng verbundene Annotator -- abhängig vom Zielsystem.\footnote
			{Angemerkt sei hierbei, dass die Implementierungen des Annotators und der Symboltabelle nicht von
			der konkreten anderen Implementierung abhängig sind.}
			Meine Implementierung der Symboltabelle hat als Zielsystem Java 1.6. Die konkrete Implementierung
			liegt in \texttt{de.{\n}fu\_berlin.{\n}compilerbau.{\n}symbolTable.{\n}java}. Die Ausnahmebehandlungsklassen
			liegen in \texttt{de.{\n}fu\_berlin.{\n}compilerbau.{\n}symbolTable.{\n}exceptions}. Die Exceptions sind
			ihrerseits unabhängig vom Zielsystem.
			
			Die Aufbau der Symboltabelle ist verhältnismäßig komplex. Um die Benutzung zu vereinfachen, habe ich
			auf ein Factory"=Pattern gesetzt. Aus dem Paket der Implementierung ist nur die Klasse von \texttt{RuntimeFactory}
			von außen sichtbar. Sämtliche anderen Klassen sind package-private. Diese Klasse wiederum hat nur eine
			public Methode:
			\begin{itemize}
				\item \verb|static Runtime newRuntime(URL[] classpath, URL rtJar)|
			\end{itemize}
			Mit dem Parameter \texttt{classpath} kann eine Liste mit JARs übergeben werden, deren Interface bei der Kompilierung
			verfügbar sein soll. Die Liste entspricht dem Parameter \texttt{-classpath} von \texttt{javac}.
			Die \texttt{rt.jar} wiederum enthält das Basissystem Javas, vornehmlich die Klassen in \texttt{java.lang}.
			Aufgrund der Benutzung der Reflexions"=API (siehe Abschnitt unter ,,\hyperlink{Offene_Baustellen_Symboltabelle}{Offene Baustellen}``)
			muss die übergebene \texttt{rt.jar} dieselbe sein, die die JVM des Compilers verwendet.
			Dieses Problem durch die Abkehr von der Reflexions"=API behoben werden.
			
			\begin{wrapfigure}{R}{0.5\textwidth}
				\caption[Vererbungshierarchie der Symbole]{Vererbungshierarchie der Symbole: \newline
					Factories gelblich hinterlegt \newline
					Metaklassen bläulich hinterlegt \newline
					qualified Symbols grün umrandet}
				\fbox{\centering
					\includegraphics[width=0.5\textwidth]{graphiken/Symboltable-inheritance.pdf}
				}
			\end{wrapfigure}
			
			Jedes Symbol hat einen Symboltypen. Die Symboltypen sind in der Klasse \texttt{SymbolType} definiert.
			Die vier bläulich hintergelben Interfaces in der Abbildung 4 haben keinen äquivalenten Symboltyp -- sie sind
			reine Metaklassen, die nur ein gemeinsames Interface der erbenden Klassen zusammenfassen, wobei
			es jedoch keine tatsächlichen Instanzen dieser Interfaces geben kann. Alle in der Abbildung grün umrandeten
			Interfaces erben von \texttt{QualifiedSymbol}.
			
			Das Interface der Symboltabelle ist streng hierarchisch aufgebaut. Es gibt die eine Basisklasse, von der
			alle anderen Interfaces (transitiv) erben. Diese strenge Hierarchie ist jedoch nur im Interface
			garantiert. In tatsächlichen Implementierungen könnten verschiedene Klassen zusammengefasst werden, um
			die Programmierung zu vereinfachen, weshalb eine Abfrage, ob ein Objekt Instanz einer bestimmten Symbolart
			nicht über \texttt{instanceof} erfolgen darf. Aus diesem Grund habe ich die Abfragemethode
			\verb|Boolean hasType(SymbolType leftType)| eingeführt. Diese gibt das Ergebnis in drei"=wertiger Logik
			zurück, wobei der Rückgabewert \texttt{null} gleichbedeutend mit unbekannt ist. Das Ergebnis \texttt{null}
			wird einerseits zurückgegeben, wenn das abgefragte Objekt unqualified ist oder \texttt{leftType} den Wert
			\texttt{UNQUALIFIED} trägt.
			
			Die Bedeutung des Parameters \texttt{leftType} ist hierbei so zu verstehen: Das abgefragte Symbol ist der
			\texttt{rightType}. Das Methode \texttt{hasType} wiederum entspricht der Implikation. Es wird also
			\texttt{true} zurückgegeben, falls $leftType\Rightarrow rightType$. Dies ist der Fall, wenn \texttt{leftType}
			in der Verberbungshierarchie über \texttt{rightType} steht, beziehungsweise, wenn beide Typen gleich sind.
			
			Die drei gelblich hinterlegten Interfaces sind Factories und können weitere Elemente erstellen, die
			sie dann enthalten. Außer durch die Factories können keine Objekte instanziiert werden. Instanzen können
			nicht an andere Container abgegeben werden. Dies soll versehentlichen Anwendungsfehlern vorbeugen.
			\begin{itemize}
				\item \texttt{Runtime}s können \texttt{Package}s erzeugen.
				\item \texttt{Package}s können \texttt{Class}es und \texttt{Interface}s erzeugen.
				\item \texttt{Class}es können \texttt{Member}s erzeugen.
				\item \texttt{Class}es und \texttt{Interface}s können \texttt{Method}s erzeugen, wobei jede Methode einen äußersten
					\texttt{Scope} enthält, abrufbar mit \texttt{Scope getScope()}.
				\item \texttt{Scope}s können \texttt{Variable}s erzeugen.
			\end{itemize}
			Sämtliche anderen Instanzen werden durch die \texttt{Runtime} erzeugt.
			
			Abfragen nach Objekten geschehen in \texttt{SymbolContainer}n und ihren Unterinterfaces. Zu diesem Zweck
			stellt das Interface die Methode
			\begin{itemize}
				\item \verb|Symbol tryGetQualifiedSymbol(PositionString name)|
			\end{itemize}
			bereit. Das zurückgegebene Symbol könnte qualified sein, falls das referenzierte Symbol bereits bekannt ist.
			Sollte das Symbol zum Zeitpunkt des Aufrufes noch nicht bekannt sein, so wird ein \texttt{UnqualifiedSymbol}
			zurückgegeben. Zu einem späteren Zeitpunkt kann ein unqualified Symbol mittels \texttt{QualifiedSymbol qualify()}
			qualifiziert werden. Sollte das Symbol dann immer noch nicht bekannt sein, so wird \texttt{null} zurückgegeben.
			Der Aufrufer muss in diesem Fall geeignet reagieren.
	
	\newpage
	\section{Anhang}
		\subsection{Abbildungs- und Quelltextverzeichnis}
			\listoffigures
			\lstlistoflistings
		
		\subsection{Lizenzierung}
			Teile des Quelltextes des Softwareprojektes Übersetzerbau 2010 stehen unter der Freien
			Lizenz \href{http://www.gnu.org/licenses/agpl-3.0.html}{GNU AGPL} in der Version 3.0.
			Die Dokumentation selbst, sowie die enthaltenen Graphiken, werden unter den Bedingungen
			der \href{http://www.gnu.org/licenses/fdl-1.3.html}{GNU FDL} in der Version 1.3 weitergegeben.
			Bindend sind nur die englischen Originaltext, die im nächsten Absatz angehängt sind.
			
			Sollten Sie den Quelltext zu anderen Konditionen weiterverwenden wollen, so setzen Sie
			sich bitte mit mir in Verbindung:
			\href{mailto:rene.kijewski@fu-berlin.de?subject=[SWP_CP_2010]}{rene.kijewski@fu"=berlin.de}.
			
			\subsubsection{Quelltext}
				\begin{multicols}{3}
					{\tiny\input{agpl}}
				\end{multicols}
			
			\subsubsection[Dieses Dokument]{Dieses Dokument}
				\begin{multicols}{3}
					{\tiny\input{gfdl}}
				\end{multicols}
\end{document}
