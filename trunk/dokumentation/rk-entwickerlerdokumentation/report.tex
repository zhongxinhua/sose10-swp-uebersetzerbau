\documentclass[10pt,a4paper,ngerman,titlepage,tocindentauto]{scrartcl}

\usepackage{jhla4}
\usepackage[T1]{fontenc}
\usepackage[utf8x]{inputenc}
\usepackage{color}
\usepackage[colorlinks=true,breaklinks=true,linkcolor=darkblue,urlcolor=darkblue]{hyperref}
\usepackage{ngerman}
\usepackage{libertine}
\usepackage{graphicx}
\usepackage{tocstyle}
\usepackage{multicol}
\usepackage{listings}
\usepackage{wrapfig}
\usepackage{placeins}

\hypersetup{
	pdftitle={Software Projekt Uebersetzerbau 2010: Entwicklerdokumentation},
	pdfauthor={Rene Kijewski},
	pdfsubject={},
	pdfcreator={},
	pdfproducer={},
	pdfkeywords={},
	pdfkeywords={}
}

\definecolor{darkblue}{rgb}{0,0,0.5}
\definecolor{crimson}{rgb}{0.862745098,0.0784313725,0.235294118}

\usetocstyle{allwithdot}
\setcounter{tocdepth}{3}
\setcounter{secnumdepth}{3}

\renewcommand{\listfigurename}{Abbildungsverzeichnis}
\renewcommand{\lstlistingname}{Quelltext}
\renewcommand{\lstlistlistingname}{Quelltextverzeichnis}

\newcommand{\xmlNote}[2]{\footnote{Spezifikation zu \href{http://www.w3.org/TR/2008/REC-xml-20081126/\#{#1}}{\texttt{#2}}.}}
\newcommand{\link}[1]{\href{#1}{#1}}
\newcommand{\TODO}{ {\LARGE\bf\color{crimson} TODO} }
\newcommand{\n}{\linebreak[1]}
\newcommand{\java}[1]{\lstinline[language=java,showstringspaces=true]{#1}}

\begin{document}
	\begin{titlepage}
		\titlehead{\includegraphics[width=\textwidth]{graphiken/Fub-logo.pdf}}
		\title{Softwareprojekt Übersetzerbau 2010} 
		\subtitle{Entwicklerdokumentation}
		\author{René Kijewski} 
		\date{18. Juli 2010 \vfill}
		\maketitle
	\end{titlepage}
	
	\begin{abstract}
		Das Softwareprojekt 2010 setzte sich zum Ziel, einen XML- nach Java"=Source"=Code"=Übersetzter
		zu schreiben.
		
		Dieses Dokument erklärt im Speziellen die Komponenten XML"=Lexer, Statement"=Lexer
		und die Symboltabelle. Es richtet sich an Entwickler und enthält deshalb gegebenenfalls
		Jargon und versucht auch nicht, Sachverhalte zu vereinfachen.
		
		Die entsprechende Kundenpräsentation, die sich nicht an Programmierer richtet, steht unter
		\link{https://dev.spline.de/svn/ss10-swp-uebersetzerbau/trunk/dokumentation/rk-kundenpraesentation/rk-kundenpraesentation.pdf}
		zur Verfügung.
	\end{abstract}

	{
		\pagestyle{empty}
		\tableofcontents
		\newpage
	}
	
	\parskip 7pt plus 5pt minus 3pt
	\setcounter{page}{1}
	\section{Einleitung}
		Das Softwareprojekt Übersetzerbau 2010 machte es sich zur Aufgabe, eine selbst"=erdachte Programmiersprache
		zu spezifizieren und einen Compiler für diese zu Implementieren.
		
		Die Projektgruppe, bestehend aus -- in alphabetischer Ordnung --
			Alexander Rau,
			Ansgar Schneider,
			Igor Merkulow,
			Markus Rudolph,
			René Kijewski und
			Stefan Meißner,
		entschied sich, eine XML"=artige Eingabesprache zu benutzen, die
		\href{http://java.sun.com/javase/6/}{Java"=SE"=6}"=kompatiblen Sourcecode ausgibt.
		Dementsprechend wurde auch Java 1.6 als Programmiersprache gewählt.
		Als einheitliche Programmierungebung wurde \href{http://www.eclipse.org/galileo/}{Eclipse Galileo} verwandt.
		Apache \href{http://subversion.apache.org/}{Subversion}, gehostet bei \href{http://dev.spline.de/}{Spline}, wurde als
		Versionskontrollsystem benutzt. Der Quelltext kann von \link{https://dev.spline.de/svn/ss10-swp-uebersetzerbau/}
		heruntergeladen werden.
		
		Ich übernahm die Komponenten XML"= und Statement"=Lexer, sowie die Implementierung einer Symboltabelle.
		
		Bei den von mir implementierten Teilprojekten achtete ich auf hohe Wiederverwendbarkeit
		und versuchte, eine Benutzung besonders einfach zu gestalten. So legte ich größeren Wert darauf,
		dass Weiternutzer die Komponenten ohne lange Einlesezeit benutzen können als auf besonders große
		Performanz. Dieser Ansatz musste leider später aufgewicht werden. In den Abschnitten
		\hyperlink{Arbeitsverlauf}{Arbeitsverlauf} und \hyperlink{Abschlussbemerkungen}{Abschlussbemerkungen}
		finden Sie weitere Informationen dazu.
		
		Um den Einstieg in die Nutzung zu Vereinfachen, verwandte ich ausgiebig die verbreitete Entwurfsmuster,
		vorrangig das \href{http://c2.com/cgi/wiki?IteratorPattern}{\em Iterator"=Patter} und die
		\href{http://c2.com/cgi/wiki?FactoryMethodPattern}{\em Factory"=Methode}.
		Beide Pattern werden im Buch {\em Design Patterns: Elements of Reusable Object"=Oriented Software}%
		\footnote{ISBN \href{https://portal.d-nb.de/opac.htm?method=simpleSearch&query=0201633612}{0-201-63361-2}}
		beschrieben und sind vielen Entwicklern von objektorientiertem Code geläufig.
		
		Die einzelnen Komponenten trennen so weit wie möglich zwischen Interface und Implementierung.
		Dies sollte es bei einer späteren Weiterarbeit am Projekt vereinfachen, die Komponenten
		auszutauschen. Bei der Spezifikationsphase überlegten wir uns unter anderem, dass auch eine
		Compilierung in Java"=Bytecode nativ möglich sein sollte.%
		\footnote{Das heißt, dass wir nicht von \texttt{javac} abhängig sein wollten.}
		Zudem sollte auch die Ausgabesprache auswechselbar sein, so dass nur das Kernstück,
		der Syntaxbaum, sowie das Interface der weiteren Komponenten, also Symboltabelle und Builder,
		unveränderlich wäre.
		
	\section{Teilprojekte}
		Die einzelnen Teilprojekte sind für sich allein verwendbar -- die Verzahnung
		mit anderen Komponenten ist minimal --, da sie jeweils am Anfang der Bearbeitungskette stehen.
		
		\begin{figure}[ht]
			\caption[Verlaufdiagramm]{Verlaufdiagramm (in diesem Dokument beschriebene Komponenten hervorgehoben)}
			\fbox{\centering
				\includegraphics[width=\textwidth]{graphiken/flowchart.pdf}
			}
		\end{figure}
		
		Die Lexer"=Komponenten benutzen jeweils einen Zeichenstrom als Eingabe. Die Rückgabedaten speichern die
		Stelle im Eingabestrom an der sie standen, so dass spätere Komponenten, wenn sie einen Fehler
		in der Eingabe feststellen, eine geeignete Meldung samt Position ausgeben können.
		Die Symboltabelle verwendet dasselbe Interface, um die Eingabeposition zu speichern, jedoch ist
		die Bedeutung an dieser Stelle wahrscheinlich geringer als bei den Lexern.
		
		\subsection{XML"=Lexer}
			Der XML"=Lexer {\em xmlNodeStream} vereinfacht die Arbeit des DOM"=Parsers, indem er die syntaxtischen
			Komponenten des Eingabestromes auftrennt, das heißt {\em tokenized}.
			Die erkannten Komponenten sind Textknoten, Kommentare, Tags, Endtags, Attribute und Processing instructions.
			
			Als Eingabeformat wird XML 1.0 verwendet.%
			\footnote{\href{http://www.w3.org/TR/2008/REC-xml-20081126/}{Extensible Markup Language (XML) 1.0 (Fifth Edition)}}
			Es wurden bewusst Eineinfachungen jedenüber dem W3-Standard vorgenommen. Unter anderem sind
			nicht wohlgeformte Ausdrücke nach Art \verb|<tag attr="a < b"/>| erlaubt.
			Dieses Beispiel wäre aufgrund des Kleiner"=Als"=Zeichens im Attributewert
			nach der Spezifikation verboten.\xmlNote{NT-AttValue}{AttValue}
			
			Die API des {\em xmlNodeStreams} ist an {\em StAX}, der \href{http://stax.codehaus.org/}{Streaming API for XML},
			angelehnt. StAX hat sich seit der Spezifikation im \href{http://jcp.org/en/jsr/detail?id=173}{JSR 173} aus
			dem Jahr 2006 als Standard für einfaches Parsen von XML"=Eingaben etabliert.
			xmlNodeStream besitzt nicht dieselbe Mächtigkeit wie StAX und erfüllt in Folge dessen
			nicht die komplette Spezifikation des W3-Consortiums, da der XML"=Prolog\xmlNote{xmldoc}{prolog}
			nicht als solcher verstanden wird:
			\begin{itemize}
				\item
					Die XML"=Deklaration\xmlNote{NT-XMLDecl}{XMLDecl} wird als
					Processing instruction\xmlNote{NT-PI}{PI} verstanden.
				\item
					Die Doctype"=Deklaration\xmlNote{NT-doctypedecl}{doctypedecl} wird nicht unterstützt.
			\end{itemize}
			Konkretere Informationen über den Informationsfluss stehen in der \hyperlink{XML-Lexer-API}{API"=Referenz}.
			
			Der XML"=Lexer überprüft die Eingabe nicht auf Wohlgeformtheit, das heißt, auch
			,,\verb|<a></b>|`` würde nicht nicht als Fehler erkannt. Dies ist eine bewusste Designentscheidung,
			die einerseits den Overhead durch eine solche Überprüfung verhindern soll -- der DOM"=Parser
			führt eh über eine Überprüfung durch -- und andererseits die Anwendungsmöglichkeiten der Implementierung
			verbreitern soll: Gewöhnliche Webseiten sind selten wohlgeformtes XML. Dadurch,
			dass {\em xmlNodeStream} agnostisch gegenüber Strukturfehlern ist, wäre er auch zum
			Lexen von Internetseiten geeignet. Fehler wie fehlende abschließende Anführungszeichen werden
			jedoch nicht übergangen, da sie eine aktive Fehlerkorrektur erforderten.
			
			{\em xmlNodeStream} implementiert das Iterator"=Interface Javas, wodurch der Einstieg in die
			Benutzung vereinfacht werden soll.
			
			\subsubsection*{Beispiel}
				\begin{lstlisting}[frame=single,language=XML,caption=Beispiel.xml]
<?xml version="1.0"?>
<module name="Test">
	Inhalt
</module>
				\end{lstlisting}
				Die Eingabedatei obenstehende XML"=Datei würde folgendermaßen erkannt:
				\begin{itemize}
					\item Processing instruction mit dem Namen \verb|xml| und Wert \verb|version="1.0"|.
					\item Öffendes Tag mit dem Namen \verb|module|.
					\item Attribute mit dem Namen \verb|name| mit dem Wert \verb|Test|.
					\item Textknoten mit dem Wert \verb|Inhalt|.
					\item Schließendes Tag mit dem Namen \verb|module|.
				\end{itemize}
				An diesem Beispiel Erkennt man, dass das jedes eingelesene Token ein Tripel aus
				Typ, Name und Wert ist, wobei Name und/oder Wert auch leer beziehungsweise \texttt{null} sein können.
			
			\begin{figure}[ht]
				\caption[Übergangstabelle der Eingabedaten]{\hypertarget{Uebergangsdiagramm_XML_Lexer}{Übergangstabelle der Eingabedaten}}
				\fbox{\centering
					\includegraphics[width=1.4\textwidth,angle=90]{graphiken/xml.pdf}
				}
			\end{figure}
			
		\subsection{Statement"=Lexer}
			Der Statement"=Lexer hat eine ähnliche Aufgabe wie der XML"=Lexer: Einen Eingabestrom in seine
			Komponenten auftrennen. Das Lexen der Statements ist die Vorstufe zum Parsen.
			
			Der Statement"=Lexer verwendet das Iterator"=Interface, wobei die Rückgabedaten
			Tupel aus dem Typen des Datums und eventuell einem zugehörigen Wert, zum Beispiel bei Strings.
			In der derzeitigen Implementierung gibt es 33 Arten von erkannten Token, sowie zwei
			Statuscodes für das Eingabeende beziehungsweise bei lexikalisch fehlerhaften Eingaben.
			Der Umfang der erkannten Eingabefehler ist gering; die Fehlererkennung geschieht im
			{\em Statement"=Parser}. Als Fehler würde unter anderem ,,\verb|1a|`` erkannt; ,,\verb|a b c|`` hingegen nicht.
			
			Die Syntax der Statements lehnt sich an Java\,SE\,6 an. Da Javas Operatoren nur ein oder
			zwei Zeichen lang sind\footnote{Der Operator \texttt{{>}>{>}} wird nicht verstanden.} und es keine Zustände wie beim
			Lexen von XML"=Daten wird, wird keine Übergangstabelle benutzt, sondern ein \verb|switch|"= und
			\verb|if|"=Konstrukt. Dies vereinfacht im Allgemeinen sowohl das Lesen und Schreiben des Lexers,
			erschwert jedoch Spezialfälle. So wird zum Beispiel zum Erkennen der Token \verb|new| und
			\verb|null| auf Tricks wie Push"=Back"=Buffer zurückgegriffen.
			Ein entscheidender Vorteil ist jedoch, dass das Einlesen der Daten wesentlich schneller
			als beim XML"=Lexer geschieht.
	
		\subsection{Symboltabelle}
			\TODO
	
	\section[Arbeitsverlauf]{\hypertarget{Arbeitsverlauf}{Arbeitsverlauf}}
		Die Programmierung des XML"=Lexers wurde bereits am 30. April begonnen; die Komponente ist deshalb
		wohl am ausführlichsten getestet. Die Aufgabe des Statement"=Lexers wiederum wurde
		am 19. Mai begonnen und die Arbeit an der Symboltabelle wurde am 28. Mai aufgenommen,
		wudurch gerade für die letzte Aufgabe ein erheblicher Zeitdruck bestand.
		
		\subsection{XML"=Lexer}
			Die Arbeit am XML"=Lexer verlief verhältnismäßig zielgerichtet. In der Vorlesung
			Übersetzerbau wurde ausgiebig erklärt, wie ein Parser geschrieben wird, so dass
			sich die tatsächliche Umsetzung als einfach erwies. Probleme ergaben sich nur,
			wenn ich Übergänge im Zustandsdiagramm (siehe \hyperlink{Uebergangsdiagramm_XML_Lexer}{Abbildung 2})
			übersah, weshalb ich sehr schnell dazu überging, das Diagramm in der Sprache
			\href{http://www.graphviz.org/doc/info/lang.html}{DOT} festzuhalten. Zeichnungen auf
			dem Papier erwiesen sich nicht als sachdienlich.
		
			\TODO
		
		\subsection{Statement"=Lexer}
			Der Statement"=Lexer wurde in kurzer Zeit geschrieben.
			
			\TODO
		
		\subsection{Symboltabelle}
			Die Arbeit an der Symboltabelle erwies sind als kompliziert. Da die Aufgabe leider sehr spät erst
			vergeben wurde und aufgrund der Anforderung, dass sie Typisierung beherrschen sollte, gehörte
			die Symboltabelle planerisch zu den größten Komponenten.
			
			
			Die Symboltabelle sollte zunächst für sämtlichen Zielsprachen gleich implementiert sein. Nachdem
			ich mich jedoch weiter in die Thematik einlas, erwies sich das nicht als möglich, da die verschiedenen
			Zielsysteme zu unterschiedlich sind. So haben verschiedene Programmiersprachen, selbst wenn man
			sich auf objektorientierte Programmiersprachen beschränkt, wenig Gemeinsamkeiten. Als Beispiele gegenüber
			Java sein die funktionale Programmiersprache \href{http://caml.inria.fr/ocaml/}{OCaml} und die prototypen"=basiere
			Programmiersprache \href{http://www.ecma-international.org/publications/standards/Ecma-262.htm}{ECMAScript}
			angeführt.
			
			Ich beschränkte mich auf die Umsetzung einer Symboltabelle, die Java 1.6 sowohl für die Ausgabe
			nach Quelltext als auch Bytecode beherrt. Das Interface wiederum sollte so generisch gehalten werden,
			dass später weitere Zielsysteme eingeführt werden könnten, wobei sich ein zu generischen Interface
			als zu kompliziert -- und damit als unbenutzbar -- erwies. Herr Rudolf gab mir des Öfteren hinweise
			auf Verbesserungsmöglichkeiten am Interface, die mir zuvor nicht einfielen. Wiederum war das Interface
			dadurch während der gesamten Entwicklungszeit einem ständigen Wandel unterlegen, wobei ich mir eigentlich
			eine schnelle Festlegung wünschte, gegen die ich die konkrete Implementierung entwickeln könnte.
			Retrospektiv kann ich sagen, dass ich mich anfangs zu wenig mit meinen anderen Teammitgliedern
			zusammengesetzt habe und deshalb nicht die Fülle der Anforderungen kannte.
			
			Bei der Programmierung an der Symboltabelle habe ich einige wertvolle Kenntnisse über die Interna
			Javas gewonnen. Gerade bei der Reflexion"=API, die einem Programm zur Laufzeit Informationen über
			das Klassen"= beziehungsweise Typsystem geben soll, habe ich erhebliche Wissensprünge gemacht,
			die ich auch für andere Kurse nutzen konnte.\footnote{Siehe zum Beispiel \href
			{https://dev.spline.de/svn/xmlproject10-group-x/trunk/controller/src/java/de/spline/dev/xmlproject10_group_x/imports/xmlContainers/Container.java}
			{\texttt{Containers.java}} des XML"=Technologien"=Projekts} Leider erwies sich die sehr einfach zu
			benutzende Reflexions"=API als Haupt"=Flaschenhals des gesamten Projektes, weshalb ich einige ,,halbherzige``
			Behelfsmaßnahmen eingebaut habe -- {\em halbherzog} deshalb, weil ich das Problem nur versteckt und
			nicht beseitigt habe. Die Reflexions"=API ist leider äußerst langsam und verbraucht große Mengen an
			RAM"=Speicher, da die Inspizierten Klassen, sowie sämtliche (transitiven) Abhängigkeiten in den Speicher
			geladen werden, wobei eigentlich nur die Struktur der Klasse bedeutsam für die Erfüllung der Aufgabe wäre.
			
			Als erste Behelfsmaßnahme werden nur noch Klassen in die Symboltabelle gelesen, die auch von außen sichtbar
			sind, das heißt entweder \texttt{public} oder \texttt{protected} sind. Default"=Private und \texttt{private}"=Klassen
			werden nicht mehr eingelesen. Jedoch offenbart diese Beschreibung bereits das größte Problem dieser Umsetzung:
			Nur weil Klassen nicht adressierbar {\em wäre}, gilt das nicht für zum Beispiel Rückgabewerte. Als weitere
			Maßnahme zum Beschleunigen habe ich das Laden parallelisiert, wodurch sich -- gefühlt --ein fast linearer Anstieg
			der Geschwindigkeit mit der Zahl der Benutzen Rechenkernen ergab.
	
	\section{Offene Baustellen}
		\TODO
	
		\subsection{XML"=Lexer}
			\TODO
	
		\subsection{Statement"=Lexer}
			\TODO
	
		\subsection{Symboltabelle}
			Um das Problem der hohen Ladezeit zu umgehen und den Speicherbedarf minimal zu halten wären zwei Ansätze,
			idealer Weise kombiniert, gangbar.
			\begin{itemize}
				\item Die Reflexions"=API ist zu mächtig und schwerfällig. Ein manuelles Auslesen der klassenstruktur
					auf Objekt"=Code"=Ebene ließe es zu, dass man unnötige Informationen nicht im Speicher hält beziehungsweise
					gar nicht erst einliest.
				\item \TODO
			\end{itemize}
			
			Auch im weiteren Programmier"= und Testverlauf erwies sich, dass die Symboltabelle optimiert werden muss, um
			nutzbar zu sein, da die Ladezeit auf Windows"=Laptops mehrere Minuten betrug. So machte es -- ich muss gestehen,
			zu meiner Verwunderung -- einen enormen Unterschied, ob eine Stringeingabe gegen $10$ oder $\log 10$ Strings verglichen
			wird, letzteres durch die Verwendung eines \verb|Set<String>|. Ein derzeit noch bestehendes Nadelöhr stellt die
			Benutzung von \texttt{TreeMap}s dar, die ich an vielen Stellen verwende, da sie im Gegensatz zu \texttt{HashMap}s
			nicht die Gefahr von Kollisionen in sich birgt. Vermutlich ist die Datenmenge klein genug, so dass es zu keinen
			Kollisionen der Streuwerte käme.
	
	\section[Abschlussbemerkungen]{\hypertarget{Abschlussbemerkungen}{Abschlussbemerkungen}}
		Eine Lexion des Projektes war, dass Besprechungen notwendig sind. Noch bevor man eine Idee umsetzt, sollte man
		sich mit den betroffenen Teammitgliedern zusammen setzten und um gemeinsam die Implikationen abzuschätzen
		oder Verbesserungsvorschläge einholen zu können. Ebenso lassen sich Beschreibungen wesentlich besser vis"=à"=vis
		vermitteln als das mit Texten möglich wäre. Als Programmierer ist man häufig zu tief in der Materie drin, als dass
		man sinnvolle Fragen abschätzen könnte, die in eine Dokumentation zu schreiben wären, wodurch zudem viel Zeit
		mit dem Schreiben unnötiger Kommentare verloren geht. Ich denke, dass Pair"=Programming das Mittel der Wahl ist,
		wenn es sich zeitlich organisieren lässt. Die Kommunikation über Chat oder Telefon kann leider nicht dasselbe leisten.
		
		Die wöchentlichen Teambesprechungen habe ich als reine Zeitverschwendung empfunden, da wöchentliche
		Berichte gerade in der Anfangsphase eines Projektes -- über die das Projekt aufgrund des Zeitdrucks
		auch nicht heraus kam -- viel zu selten sind und man zu viele für einen selbst unrelevante Informationen
		anhören muss, so dass das Aufmerksamkeitsfenster bei relevanten Dingen bereits wieder geschlossen
		sein kann. Dass die Teambesprechungen in unserem Fall um acht Uhr morgens waren, war der Aufmerksamkeit
		ebenso nicht zuträglich.
		
		\TODO
		
	\section{API"=Referenz}
		\subsection[XML-Lexer]{\hypertarget{XML-Lexer-API}{XML"=Lexer}}
			Der XML"=Lexer trennt zwischen Interface und Implementierung.
			Das Package des Interfaces heißt \texttt{de.{\n}fu\_berlin.{\n}compilerbau.{\n}xmlNodeStream};
			die Implementierung befindet sich unter \texttt{de.{\n}fu\_berlin.{\n}compilerbau.{\n}xmlNodeStream.{\n}impl}.
			
			\subsubsection*{Interface}
				\begin{wrapfigure}{R}{0.3\textwidth}
					\vspace{-22pt}
					\caption{Mög\-li\-che Rück\-ga\-be\-wer\-te des State\-ment"=Le\-xers nach Zu\-stand}
					\fbox{\centering
						\includegraphics[width=0.3\textwidth]{graphiken/Ausgaben.pdf}
					}
					\vspace{-30pt}
				\end{wrapfigure}
				
				Das Interface defininiert in \texttt{NodeType.java} die Arten der zu erkennenden Knoten.
				Dies sind derzeit \texttt{NT\_TEXT}, \texttt{NT\_COMMENT}, \texttt{NT\_TAG}, \texttt{NT\_END\_TAG},
				\texttt{NT\_ATTR}, \texttt{NT\_PI}, sowie für fehlerhaften Eingaben \texttt{NT\_ERROR}.
				
				Ein einzelnes gelesenes Token wird in einem \texttt{XmlNode} zurückgegeben, welches die Methoden
				\texttt{NodeType getType()}, \texttt{PositionString getKey()} und \texttt{PositionString getValue()}
				besitzt. Nicht für alle Tokenarten sind sowohl Key also auch Value gesetzt. Konsultieren dafür
				bitte das entsprechende JavaDoc für \texttt{XmlNode}. Ein \texttt{XmlNode} implementiert das Interface
				\texttt{StreamPosition}.
				
				Die letzte Komponente des Interfaces des XML"=Lexers stellt \texttt{XmlNodeStream} dar, welches
				angibt, dass die XmlNodeStreams das Interface \texttt{Iterable<{\n}XmlNode>}, \texttt{StreamPosition} und
				\texttt{Closeable} erfüllen müssen.
				
				Wie in Abbildung 3 zu sehen, kann der XmlNodeStream nicht an jeder Stelle ein beliebiges Token zurückgeben.
				So kann unter anderem \texttt{NT\_ATTR} nur auf \texttt{NT\_ATTR} oder \texttt{NT\_TAG} folgen.
				Bei der Benutzung von \texttt{XmlNodeStreamFactory} darf man sich darauf verlassen, dass dieser Contract
				nicht verletzt wird.
			
			\subsubsection*{Implementierung}
				Die Implementierung verfügt nur über eine öffentlich sichtbare Klasse, nämlich \texttt{XmlNodeStreamFactory}.
				Die Klasse verfügt über drei statische Factory"=Methoden
				\begin{itemize}
					\item \texttt{static XmlNodeStream createNewInstance(PositionString str);}
					\item \texttt{static XmlNodeStream createNewInstance(Reader reader);}
					\item \texttt{static XmlNodeStream createNewInstance(Reader reader, StreamPosition pos);}
				\end{itemize}
				Wobei die ersten beiden Methoden Wrapper für die letzte Methode darstellen.
	
		\subsection{Statement"=Lexer}
			\TODO
	
		\subsection{Symboltabelle}
			\TODO
	
	\section{Anhang}
		\subsection{Abbildungs- und Quelltextverzeichnis}
			\listoffigures
			\lstlistoflistings
		
		\subsection{Lizenzierung}
			Teile des Quelltextes des Softwareprojektes Übersetzerbau 2010 stehen unter der Freien
			Lizenz \href{http://www.gnu.org/licenses/agpl-3.0.html}{GNU AGPL} in der Version 3.0.
			Die Dokumentation selbst, sowie die enthaltenen Graphiken, werden unter den Bedingungen
			der \href{http://www.gnu.org/licenses/fdl-1.3.html}{GNU FDL} in der Version 1.3 weitergegeben.
			Bindend sind nur die englischen Originaltext, die im nächsten Absatz angehängt sind.
			
			Sollten Sie den Quelltext zu anderen Konditionen weiterverwenden wollen, so setzen Sie
			sich bitte mit mir in Verbindung:
			\href{mailto:rene.kijewski@fu-berlin.de?subject=[SWP_CP_2010]}{rene.kijewski@fu"=berlin.de}.
			
			\subsubsection{Quelltext}
				\begin{multicols}{3}
					{\tiny\input{agpl}}
				\end{multicols}
			
			\subsubsection[Dieses Dokument]{Dieses Dokument}
				\begin{multicols}{3}
					{\tiny\input{gfdl}}
				\end{multicols}
\end{document}
